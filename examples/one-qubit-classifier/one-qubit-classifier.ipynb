{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> NISQAI: One-Qubit Quantum Classifier </p> \n",
    "<p style=\"text-align: center;\"> Ryan LaRose, Yousif Almulla, Nic Ezzell, Joe Iosue, Arkin Tikku </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote cite=\"\">\n",
    "\"Quantum computing needs more quantum software engineers to implement, test, and optimize quantum algorithms.\"\n",
    "    -- Matthias Troyer.\n",
    "</blockquote>\n",
    "\n",
    "<blockquote cite=\"\">\n",
    "\"Experimentation on quantum testbeds is needed.\" -- John Preskill.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Header image, quantum circuits over a neural network.](./header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> What is NISQAI? </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantum machine learning is an exciting but conjectural field that lacks testing on quantum computers. NISQAI is a library written to facilitate research in artificial intelligence on current quantum computers and NISQ (noisy intermediate-scale quantum) devices. \n",
    "\n",
    "In this notebook, we demonstrate the steps toward a quantum neural network working as a simple classifier. We then demonstrate how easily the NISQAI library can facilitate this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> Requirements for this Notebook </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you're reading this, you probably have a working installation of [Python](https://www.python.org/) and/or [Jupyter](http://jupyter.org/). In order to run this notebook, the following external packages are necessary. Installation instructions can be found by following the hyperlinks for each.\n",
    "\n",
    "* [NumPy](http://www.numpy.org/)\n",
    "* [SciPy](https://www.scipy.org/)\n",
    "* [pyQuil](https://pyquil.readthedocs.io/en/stable/) 2.1.0\n",
    "* [Matplotlib](https://matplotlib.org/)\n",
    "* [QuTiP](http://qutip.org/docs/4.1/index.html) 4.1.0 (only for Bloch sphere visualization features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtins\n",
    "import time\n",
    "\n",
    "# standard imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# library imports\n",
    "from pyquil.quil import Program\n",
    "from pyquil import api\n",
    "import pyquil.gates as ops\n",
    "from qutip import Bloch, ket\n",
    "\n",
    "# option for notebook plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> Quantum Neural Networks: A Five Step Process </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement a neural network for classical data on a quantum computer (i.e., a _quantum neural network_), the following steps need to be performed.\n",
    "\n",
    "1. Data encoding.\n",
    "    * Encode the classical data into a form suitable for the quantum circuit.\n",
    "1. State preparation.\n",
    "    * Implement a quantum circuit preparing the state of a particular datum.\n",
    "1. Unitary evolution.\n",
    "    * Implement a parameterized gate sequence to transform the data.\n",
    "1. Measurement/non-linearity.\n",
    "    * Measure the state of the quantum data after unitary evolution to revert back to classical information.       * Non-linearity can be introduced at this point via classical processing.\n",
    "1. Training/cost function.\n",
    "    * Define a cost function and optimize the parameters of the unitary to minimize the cost.\n",
    "    \n",
    "In the rest of the notebook, we'll go over how to do each of these steps in turn for a simple classification problem. At the end of the notebook, we'll show how easily this can be done with the NISQAI library and discuss other features of NISQAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> Problem Description </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific problem we look it in this notebook falls under the category of _supervised machine learning_. Specifically, we ask:\n",
    "\n",
    "_Given $N$ data points $p = (x, y) \\in \\mathbb{R}^2$ with labels $z(p) = 1$ if $x \\le 0.5$ and $z(p) = 0$ otherwise, learn the decision boundary and classify new points._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: center;\"> 1. Data Encoding  </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run a quantum neural network on classical data, the classical data needs to be suitably encoded to allow it to be \"uploaded\" to a quantum computer. We demonstrate a simple encoding scheme below for $(x, y)$ Cartesian coordinates distributed uniformly in a unit square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: center;\"> Generating Data  </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate a random set of classical data. For reproducibility, we'll seed our random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducible results\n",
    "SEED = 1059123109\n",
    "np.random.seed(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data points distributed uniformly at random in [0, 1) x [0, 1)\n",
    "npoints = 400\n",
    "data = np.zeros((npoints, 2))\n",
    "dx = np.linspace(0, 1, 20)\n",
    "\n",
    "for j in range(20):\n",
    "    data[j * len(dx) : (j + 1) * len(dx), 0] = dx[j]\n",
    "    data[j * len(dx) : (j + 1) * len(dx), 1] = dx\n",
    "\n",
    "# npoints = 100\n",
    "# data = np.random.rand(npoints, 2)\n",
    "\n",
    "def predicate(point):\n",
    "    \"\"\"Returns true if the point satisfies the predicate, else false.\"\"\"\n",
    "    return True if point[0] <= point[1] else False\n",
    "\n",
    "# separate the data with a linear boundary y = x\n",
    "labels = np.array([1 if predicate(p) else 0 for p in data])\n",
    "\n",
    "# plot the line y = x\n",
    "xs = np.linspace(0, 1, 100)\n",
    "ys = 0.5 * np.ones_like(xs)\n",
    "plt.plot(xs, xs, '--k')\n",
    "\n",
    "# plot the data with the color key BLUE = 0 = LEFT, GREEN = 1 = RIGHT\n",
    "for i in range(npoints):\n",
    "    if labels[i] == 0:\n",
    "        ckey = 'g'\n",
    "    else:\n",
    "        ckey = 'b'\n",
    "    plt.scatter(data[i, 0], data[i, 1], color=ckey)\n",
    "    \n",
    "# title and axis lables\n",
    "#plt.title(\"Random Data Points in Unit Square\", fontweight=\"bold\", fontsize=16)\n",
    "\n",
    "# put on a grid and show the plot\n",
    "plt.grid()\n",
    "# plt.savefig(\"graph.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: center;\"> Qubit Encoding </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we implement a method of data encoding that we call \"qubit encoding.\" Qubit encoding works by writing two bits of classical information into one bit of quantum information. How is this done? Note that any qubit can be written\n",
    "\n",
    "\\begin{equation}\n",
    "|\\psi\\rangle = \\alpha |0\\rangle + \\beta |1\\rangle\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha, \\beta \\in \\mathbb{C}$ satisfying $|\\alpha|^2 + |\\beta|^2 = 1$. Because of this normalization condition, we may equivalently write\n",
    "\n",
    "\\begin{equation}\n",
    "|\\psi\\rangle = \\cos(\\theta / 2) |0\\rangle + e^{i \\phi} \\sin(\\theta / 2)|1\\rangle\n",
    "\\end{equation}\n",
    "\n",
    "We then encode information into the phases $0 \\le \\theta \\le \\pi$ and $ 0 \\le \\phi \\le 2 \\pi$. \n",
    "\n",
    "For the $(x, y)$ coordinates of our points, we will use the encoding\n",
    "\n",
    "\\begin{align}\n",
    "\\theta &= \\pi x \\\\\n",
    "\\phi &= 2 \\pi y\n",
    "\\end{align}\n",
    "\n",
    "This is a simple encoding, but the results of the classification will speak to it's effectivenss. Other encodings, for example\n",
    "\n",
    "\\begin{align}\n",
    "\\theta &= \\frac{1}{2} \\tan^{-1}\\left( \\frac{y}{x} \\right) \\\\\n",
    "\\phi &= \\pi (x^2 + y^2),\n",
    "\\end{align}\n",
    "\n",
    "can be used for other data sets.\n",
    "\n",
    "In code, we may make this transformation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the classical data via a simple linear \"qubit encoding\"\n",
    "qdata = np.zeros_like(data)\n",
    "for (index, point) in enumerate(data):\n",
    "    qdata[index][0] = np.pi * (point[0] + 0.0 * point[1]) / 1.0\n",
    "    qdata[index][1] = 2 * np.pi * (0.0 * point[0] + point[1]) / 1.0\n",
    "#     qdata[index][0] = np.pi * point[0]\n",
    "#     qdata[index][1] = 2 * np.pi * point[1]\n",
    "#     qdata[index][0] = 2 * np.arcsin(point[0])\n",
    "#     qdata[index][1] = 4 * np.arccos(point[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now possible to visualize the data as points on the surface of the Bloch sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break the data into two lists depending on label and turn into (x, y, z) points\n",
    "\n",
    "# empty lists to store values\n",
    "gxs = []\n",
    "gys = []\n",
    "gzs = []\n",
    "bxs = []\n",
    "bys = []\n",
    "bzs = []\n",
    "\n",
    "# loop over all points, convert to cartesian coords, and append to correct list\n",
    "for (index, point) in enumerate(qdata):\n",
    "    theta = point[0]\n",
    "    phi = point[1]\n",
    "    sin = np.sin(theta)\n",
    "    # convert to cartesian coords for plotting\n",
    "    x = np.sin(theta) * np.cos(phi)\n",
    "    y = np.sin(theta) * np.sin(phi)\n",
    "    z = np.cos(theta)\n",
    "    if labels[index] == 0:\n",
    "        gxs.append(x)\n",
    "        gys.append(y)\n",
    "        gzs.append(z)\n",
    "    else:\n",
    "        bxs.append(x)\n",
    "        bys.append(y)\n",
    "        bzs.append(z)\n",
    "\n",
    "# format points correctly for bloch sphere\n",
    "lpoints = [gxs, gys, gzs]\n",
    "rpoints = [bxs, bys, bzs]\n",
    "\n",
    "# get a Bloch sphere\n",
    "bloch = Bloch()\n",
    "\n",
    "# options for Bloch sphere\n",
    "bloch.frame_color = \"grey\"\n",
    "bloch.sphere_color = \"white\"\n",
    "bloch.point_size = [40]\n",
    "bloch.sphere_alpha = 0.50\n",
    "bloch.point_color = [\"g\", \"b\"]\n",
    "bloch.point_marker = [\"o\"]\n",
    "bloch.view = [-55, 10]\n",
    "\n",
    "# add the points on the Bloch sphere\n",
    "bloch.add_points(lpoints)\n",
    "bloch.add_points(rpoints)\n",
    "    \n",
    "# show the Bloch sphere\n",
    "#bloch.save(\"lin-comb-bloch.pdf\", format=\"pdf\")\n",
    "%matplotlib notebook\n",
    "bloch.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: center;\"> 2. State Preparation </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have encoded our data, we still need to prepare it in quantum form. Conventionally, all qubits start in the $|0\\rangle$ state. The problem we have to solve is:\n",
    "\n",
    "Given angles $\\theta, \\phi$, perform the mapping\n",
    "\n",
    "\\begin{equation}\n",
    "S(\\theta, \\phi) |0\\rangle \\rightarrow |\\psi\\rangle = \\cos(\\theta / 2) |0\\rangle + e^{i \\phi} \\sin(\\theta / 2)|1\\rangle\n",
    "\\end{equation}\n",
    "\n",
    "We call $S$ a _state preparation unitary_ or _state preparation circuit_.\n",
    "\n",
    "It is clear from the equation above that the matrix representation for $S$ in the computational basis is\n",
    "\n",
    "\\begin{equation}\n",
    "S(\\theta, \\phi) = \\left[ \\begin{matrix} \n",
    "\\cos(\\theta / 2) & e^{-i \\phi} \\sin(\\theta / 2)\\\\\n",
    "e^{i \\phi} \\sin(\\theta / 2) & - \\cos(\\theta / 2)  \\\\\n",
    "  \\end{matrix} \\right]\n",
    "\\end{equation}\n",
    "\n",
    "On current NISQ computers, circuits need to be as short-depth as possible, meaning they contain as few gates as possible. The \"qubit encoding\" performed above allows for a constant-depth state preparation circuit for any given values of $\\theta, \\phi$.\n",
    "\n",
    "Why is this? In general we need to perform some arbitrary unitary transformation $S \\in SU(2)$. It is known that such a unitary can be implemented with five standard rotations that can be implemented by current quantum computers. Namely,\n",
    "\n",
    "\\begin{equation}\n",
    "S = R_z(\\gamma_1) R_x(\\pi / 2) R_z(\\gamma_2) R_x(\\pi / 2) R_z(\\gamma_3)\n",
    "\\end{equation}\n",
    "\n",
    "where $0 \\le \\gamma_i \\le 2 \\pi$ for $i = 1, 2, 3$. We can define our gate $S$ above in pyquil and compile it to a sequence of five implementable rotations by using the Quil compiler. First we'll write a function to give us our state preparation matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the matrix S as a function of theta and phi\n",
    "def state_prep_mtx(theta, phi):\n",
    "    \"\"\"Returns the state preparation matrix according to the qubit encoding above.\"\"\"\n",
    "    return np.array([[np.cos(theta / 2), np.exp(-1j * phi) * np.sin(theta / 2)],\n",
    "                     [np.exp(1j * phi) * np.sin(theta / 2), - np.cos(theta / 2)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll define this as a pyquil gate. We do this by first making a program then defining a gate for a particular encoded data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a pyquil program\n",
    "qprog = Program()\n",
    "\n",
    "# pick a particular encoded data point\n",
    "theta, phi = qdata[0]\n",
    "\n",
    "# get the state prep matrix for this point\n",
    "S = state_prep_mtx(theta, phi)\n",
    "\n",
    "# define a gate in pyquil for the state preparation\n",
    "qprog.defgate(\"S\", state_prep_mtx(theta, phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this gate in a quantum program to input our classical data into the quantum computer. To do this, we simply write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the first encoded data point in quantum form\n",
    "qprog += (\"S\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see our program, we can print it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qprog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we measure this qubit now, we get either a zero or a one with probability proportional to it's amplitudes. We'll add this measurement to our program and then run it many times to get an estimate of the probability distribution of it's outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a measurement on the qubit encoding our data\n",
    "creg = qprog.declare(\"ro\", memory_size=1)\n",
    "qprog += (ops.MEASURE(0, creg[0]))\n",
    "\n",
    "# print out the new program\n",
    "print(qprog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the program many times\n",
    "shots = 1000\n",
    "qvm = api.QVMConnection()\n",
    "dist = qvm.run(qprog, trials=shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(dist):\n",
    "    \"\"\"Makes a histogram of the probability of obtaining 0 and 1.\"\"\"\n",
    "    # get the zero and one probabilities\n",
    "    prob0 = dist.count([0]) / shots\n",
    "    prob1 = dist.count([1]) / shots\n",
    "    \n",
    "    # make a bar plot\n",
    "    plt.bar([0, 1], [prob0, prob1])\n",
    "    \n",
    "    # make it look nice\n",
    "    plt.grid()\n",
    "    plt.title(\"Output Probability Distribution\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Measurement Outcomes\", fontsize=14)\n",
    "    plt.ylabel(\"Probability\", fontsize=14)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks([0, 1])\n",
    "    \n",
    "    # show it\n",
    "    plt.show()\n",
    "\n",
    "# make a histrogram of the output distribution\n",
    "histogram(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our output distribution to move towards either zero or one, depending on what label is assigned to that particular data point. To do this, we implement unitary evolution on the circuit, which corresponds to implementing another sequence of gates in our circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: center;\"> 3. Unitary Evolution </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the classical data has been encoded (step 1) and prepared into the quantum system (step 2), step 3 is to perform unitary evolution on the quantum state representing the data. In the language of classical learning theory, this corresponds to implementing a layer of the neural network.\n",
    "\n",
    "In the quantum neural network case, we simply need to implement a sequence of parameterized gates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we write a function to easily implement such a unitary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitary(angles):\n",
    "    \"\"\"Returns a circuit implementing the unitary Rz(theta0) P Rz(theta1) P Rz(theta2)\n",
    "    where thetea0 = angles[0], theta1 = angles[1], and theta2 = angles[2] and\n",
    "    P = Rx(pi / 2) is a pi / 2 pulse.\n",
    "    \"\"\"\n",
    "    return Program(\n",
    "        ops.RZ(angles[0], 0),\n",
    "        ops.RX(np.pi / 2, 0),\n",
    "        ops.RZ(angles[1], 0),\n",
    "        ops.RX(np.pi / 2, 0),\n",
    "        ops.RZ(angles[2], 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use it to add unitary evolution to our quantum neural network for some given angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test angles\n",
    "angles = 2 * np.pi * np.random.rand(3)\n",
    "\n",
    "# pop off measurement\n",
    "qprog.pop()\n",
    "\n",
    "# append the unitary circuit to our quantum neural network program\n",
    "qprog += unitary(angles)\n",
    "qprog += [ops.MEASURE(0, creg[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qprog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run this new circuit with the unitary evolution implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the quantum neural network program\n",
    "histogram(qvm.run(qprog, trials=shots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use this unitary evolution to move our output probability towards the desired label. We'll suppose for a moment that this point is supposed to be mapped to the 0 output. We'll define an objective function ```obj_simple(angles)``` to capture the amount of 1 outputs, then we'll train over the angles in the unitary to minimize the objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_program(pangles, uangles):\n",
    "    \"\"\"Returns a pyquil program that prepares the state according\n",
    "    to pangles and applies the unitary according to uangles.\n",
    "    \"\"\"\n",
    "    # instantiate a program\n",
    "    qprog = Program()\n",
    "    creg = qprog.declare(\"ro\", memory_size=1)\n",
    "    \n",
    "    # define a gate in pyquil for the state preparation\n",
    "    qprog.defgate(\"S\", state_prep_mtx(pangles[0], pangles[1]))\n",
    "\n",
    "    # write the program(\n",
    "    qprog += [(\"S\", 0),\n",
    "             unitary(uangles),\n",
    "             ops.MEASURE(0, creg[0])]\n",
    "    \n",
    "    return qprog\n",
    "\n",
    "def obj_simple(angles, shots=1000, verbose=False):\n",
    "    \"\"\"Returns the number of zero outputs of a single training example.\"\"\"\n",
    "    # make the program\n",
    "    qprog = make_program([theta, phi], angles)\n",
    "    if verbose:\n",
    "        print(qprog)\n",
    "    dist = qvm.run(qprog, trials=shots)\n",
    "    obj = dist.count([1]) / shots\n",
    "    print(\"The current value of the objective function is:\", obj, end=\"\\r\")\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll minimize the objective function `obj_simple` by using the modifed `Powell` algorithm builtin to SciPy. The minimization here should take no more than 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = minimize(obj_simple, x0=2 * np.pi * np.random.rand(3), method=\"Powell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can verify that the output distribution skews this point towards the \"zero bin.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the circuit (neural network) with the optimal parameters\n",
    "%matplotlib inline\n",
    "opt_angles = out['x']\n",
    "qprog = make_program([theta, phi], opt_angles)\n",
    "\n",
    "# show the output distribution\n",
    "dist = qvm.run(qprog, trials=shots)\n",
    "histogram(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed it does! Here we demonstrated that we can use our neural network to \"steer\" a point in a particular direction. The idea of training is to \"steer\" _all_ points in the desired direction. Before we train our quantum neural network, we first discuss the measurement process and it's importance in quantum neural network implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: center;\"> 4. Measurement  </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measurement is used in our circuit above to translate from quantum to classical information. In other quantum neural networks, measurement can be used to introduce non-linearity.\n",
    "\n",
    "NISQAI treats measurements as both a way to keep circuit-depth low (for implementations on current/near-term quantum computers) as well as introduce non-linearity between layers of a network. Specifically, measuremnets lead to (intermediate) classical data. On a classical computer, we can introduce any non-linear activation function we wish. The new classical data from the output of the activation function can then be prepared into quantum form again via steps 1 and 2 (data encoding and state preparation).\n",
    "\n",
    "This intermediate classical post-processing is a trademark of NISQAI. It allows for:\n",
    "\n",
    "1. Short-depth circuits suitable for NISQ computers.\n",
    "1. Non-linearity between layers of a quantum neural network.\n",
    "1. Deep learning (many layers) with shallow circuits.\n",
    "\n",
    "In this simple binary classifier example, we'll restrict to just one layer of the neural network for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: center;\"> 5. Training </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw above that it's easy to steer one point towards the output we want to get. But training the quantum neural network involves training over all points in the training set. For this, we need to define a cost function that captures the total loss over the entire training set.\n",
    "\n",
    "To do this, define the _indicator function_ $I(z_i = \\hat{z}_i)$ to be 0 if $z_i = \\hat{z}_i$ and 1 otherwise. Here, $z_i$ is the exact label of the $i$th training data $(x_i, y_i)$ and $\\hat{z}_i$ is the prediction of this label by our neural network. (In code, we use the variables `labels` for $z_i$ and `predictions` for $\\hat{z}_i$.)\n",
    "\n",
    "To define the cost now, we simply sum over all points (say there are $M$ points) in the training data:\n",
    "\n",
    "\\begin{equation}\n",
    "C = \\sum_{i = 1}^{M} I(z_i = \\hat{z}_i)\n",
    "\\end{equation}\n",
    "\n",
    "Note that the cost $C$ depends on the unitary evolution $U$, i.e. $C = C(U)$, because the prediction $\\hat{z}_i$ depends on $U$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to define a cost (objective) function ```obj(...)``` that takes into account all data in the training set. This function will encapsulate everything we've done for a single training point, but now for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of total data to use as training data\n",
    "train_frac = 0.7\n",
    "\n",
    "def obj(uangles):\n",
    "    \"\"\"Returns the objective function C defined above over all training data.\n",
    "    \n",
    "    Args:\n",
    "        uangles [type: list<float>]\n",
    "            the angles in the unitary evolution.\n",
    "\n",
    "    rtype: int\n",
    "    \"\"\"\n",
    "    # grab some training data from the overall data set\n",
    "    tpoints = int(train_frac * len(qdata))\n",
    "    tdata = qdata[:tpoints]\n",
    "    tlabels = labels[:tpoints]\n",
    "    \n",
    "    # initialize a variable to store the output predictions of the neural net\n",
    "    predictions = np.zeros_like(tlabels, dtype=int)\n",
    "    \n",
    "    # loop over all training data to get the predictions\n",
    "    for i, pangles in enumerate(tdata):\n",
    "        # write the program\n",
    "        qprog = make_program(pangles, uangles)\n",
    "        \n",
    "        # run the program\n",
    "        out = qvm.run(qprog, trials=1000)\n",
    "        \n",
    "        # get the output probabilities\n",
    "        p0 = out.count([0])\n",
    "        p1 = out.count([1])\n",
    "        \n",
    "        # take the prediction to be max(p0, p1)\n",
    "        if p0 >= p1:\n",
    "            predictions[i] = 0\n",
    "        else:\n",
    "            predictions[i] = 1\n",
    "        \n",
    "    # compute the difference of the labels and return the cost\n",
    "    cost = sum(abs(predictions - tlabels)) / tpoints\n",
    "    print(\"The current value of the cost function is:\", cost, end=\"\\r\")\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the objective function for some random test angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random angles\n",
    "angs = 2 * np.pi * np.random.rand(3)\n",
    "cost = obj(angs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want just any random angles for our unitary evolution, however. We want to compute the optimal angles, which we can do by minimizing the cost function. Again we'll use the modified ```Powell``` algorithm for minimization.\n",
    "\n",
    "Training the neural network here will take more time than simply optimizing the output of a single point. On our computer, it takes around 15 seconds to evaluate the objective function for one set of angles. The `Powell` optimization algorithm generally takes on the order of 20-30 cost function evaluations--for us the optimization takes around 15 minutes on average. You can expect this training to take 15-20 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're in a hurry and don't want to wait for this training, we've saved a set of optimal angles from previous attempts. These angles are for a horizontal boundary $x = 0.5$ trained on 70/100 data points. They will only be optimal for the first set of random points generated by the given seed. We reiterate: _Only use these angles if you haven't changed anything in the notebook and only ran each cell once!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_angles = [7.85082205, 0.01934754, 9.62729993]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you chose to skip the training, you should *not* execute the next two cells. Otherwise, continue through the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the quantum neural network and time how long it takes\n",
    "start = time.time()\n",
    "out = minimize(fun=obj, x0=angs, method=\"Powell\")\n",
    "print(\"\\nTotal training runtime took {} minutes.\".format((time.time() - start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the optimal angles and minimal cost value\n",
    "optimal_angles = out['x']\n",
    "fval = out['fun']\n",
    "\n",
    "# print them out\n",
    "print(fval)\n",
    "print(optimal_angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> Results  </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained on a subset of our data, we can see how the predictions do on the whole dataset.\n",
    "\n",
    "First, we'll write a function that performs this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_predictions(angles):\n",
    "    \"\"\"Returns a numpy array of all predictions.\"\"\"\n",
    "    # initialize a variable to store the output predictions of the neural net\n",
    "    zhats = np.zeros_like(labels, dtype=int)\n",
    "    \n",
    "    # loop over all data to get predictions\n",
    "    for i, pangles in enumerate(qdata):\n",
    "        # write the program\n",
    "        qprog = make_program(pangles, angles)\n",
    "        \n",
    "        # run the program\n",
    "        out = qvm.run(qprog, trials=1000)\n",
    "        \n",
    "        # get the output probabilities\n",
    "        p0 = out.count([0])\n",
    "        p1 = out.count([1])\n",
    "        \n",
    "        # take the prediction to be max(p0, p1)\n",
    "        if p0 >= p1:\n",
    "            zhats[i] = 0\n",
    "        else:\n",
    "            zhats[i] = 1\n",
    "    return zhats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll call the function to get the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute all the predictions of the quantum neural network\n",
    "predictions = get_all_predictions(optimal_angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now trained our neural network and classifeid all data points. Let's display the statistics below to see how our QNN performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num = 0\n",
    "\n",
    "for a in np.linspace(0, 2 * np.pi, 25):\n",
    "    for b in np.linspace(0, 2 * np.pi, 25):\n",
    "        num += 1\n",
    "        \n",
    "        # compute all the predictions of the quantum neural network\n",
    "        predictions = get_all_predictions([a, b, 0])\n",
    "\n",
    "# # compute statistics of the QNN\n",
    "# ntrain = int(train_frac * npoints)\n",
    "# ncorrect = npoints - sum(abs(predictions - labels))\n",
    "# acc = ncorrect / npoints * 100\n",
    "\n",
    "# # print them out\n",
    "# print(\" Results of quantum neural network classification \".center(80, \"=\"))\n",
    "# print(\"Out of {} total data points:\".format(npoints))\n",
    "# print(\"The QNN was trained on {}% of the total data ({} training points).\".format(train_frac * 100, ntrain))\n",
    "# print(\"The QNN classified {} data points correctly ({}% accuracy).\".format(ncorrect, acc))\n",
    "# print(\"\".center(80, \"=\"))\n",
    "# % matplotlib inline\n",
    "# # plot the points, line y = x, and prediction\n",
    "# #plt.plot(xs, xs, '--k')\n",
    "        for i in range(npoints):\n",
    "            if predictions[i] == 0:\n",
    "                ckey = 'g'\n",
    "            else:\n",
    "                ckey = 'b'\n",
    "            plt.scatter(data[i, 0], data[i, 1], color=ckey)\n",
    "\n",
    "        plt.grid()\n",
    "        plt.title(\"a = %0.2f, b = %0.2f\" %(a, b), fontsize=16, fontweight=\"bold\")\n",
    "        plt.savefig(str(num) + \".png\", format=\"png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: center;\"> Discussion of Results </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did your quantum neural network perform? If you followed through this notebook sequentially, you should have seen 100% accuracy in the predictions of the network. A saved plot of our results obtained by running this notebook is included below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QNN Predictions](qnn-predictions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the exact decision boundary (not the learned one) is shown in the plot, and data points are colored according to the quantum neural network predictions. Blue means predicted left of the boundary (0 bin), and green means predicted right of the boundary (1 bin). As can be seen in our example results, all data points are correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> Example Done with NISQAI  </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example involved five steps to implementing a neural network on a quantum computer. While the steps aren't hard, programming each one for every particular example is tedious and time consuming. More time could be spent testing quantum neural networks if there were a library to implement all of these steps.\n",
    "\n",
    "This is where NISQAI comes in. NISQAI is to quantum machine learning what TensorFlow/pyTorch is to classical machine learning. Just like OpenFermion provides a library of code to simplify quantum chemistry on quantum computers, NISQAI provides a library of code to simplify neural networks and other machine learning algorithms on quantum computers.\n",
    "\n",
    "The above classifier example in NISQAI could be done with the following few lines of code. Here, we assume that ```classical_data``` exists in the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype NISQAI Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# imports\n",
    "from nisqai import qnn\n",
    "\n",
    "# get a quantum neural network\n",
    "network = qnn.qnn(nodes=1, layers=1)\n",
    "\n",
    "# encode the classical data into quantum form\n",
    "network.encode(data=classical_data, scheme=qnn.encoding_schemes.SIMPLE_LINEAR)\n",
    "\n",
    "# add the unitary evolution\n",
    "network.add_unitary(qnn.ansatze.UNIVERSAL)\n",
    "\n",
    "# add measurements to the network\n",
    "network.add_measurements(basis=qnn.bases.Z)\n",
    "\n",
    "# do the training on 70% of the total data\n",
    "network.train(optimizer=\"Powell\", fraction=0.7)\n",
    "\n",
    "# test the neural network on all the data or on new input data\n",
    "statistics = network.classify()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These few lines of code show the power of NISQAI. One of it's greatest strengths is the flexibility to research other quantum neural network implementations, not just the one qubit quantum classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features of NISQAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Shatters domain barriers.\n",
    "    * Whether you're a machine learning researcher interested in quantum or a quantum researcher interested in machine learning, NISQAI is built for you.\n",
    "* Powerful builtins.\n",
    "    * Numerous prototypes of quantum neural network architectures, including methods for data encoding, state preparation, unitary evolution, measurement, and training.\n",
    "* Fully modular.\n",
    "    * For methods like `qnn.add_unitary(...)`, the user can write a function to specify whichever unitary ansatz is desired.\n",
    "* Loaded with examples.\n",
    "    * Many instructive code snippets and notebooks to get you started in quantum machine learning.\n",
    "* Open-source.\n",
    "    * NISQAI is currently under development with expected release in early 2019. After this, NISQAI will be free and open-source. Always.\n",
    "* Cross platform.\n",
    "    * NISQAI works for Windows, Mac, and Linux.\n",
    "* Python/Matlab interfaces.\n",
    "    * Two of the most popular languages for quantum computing and machine learning researchers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we've seen that a quantum neural network is able to successfully classify classical data in $\\mathbb{R}^2$. The qubit encoding strategy is able to write two bits of classical information into one bit of quantum information. Additionally, the state preparation circuit for the qubit encoding is short-depth, particularly useful for NISQ computers. We've demonstrated how to train a quantum neural network using the modified Powell algorithm on a simple example. We've also discussed how the NISQAI library greatly simplifies quantum neural network implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The development of NISQAI is supported by the [unitary.fund](http://unitary.fund/). We thank [Will Zeng](https://twitter.com/wjzeng) for creating and running this program, as well as [John Hering](https://twitter.com/johnhering), Jeff Cordova, Nima Alidoust, and [PLOS](https://www.plos.org/) for sponsoring it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
